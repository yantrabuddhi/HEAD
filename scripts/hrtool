#!/usr/bin/env bash
#
# hrtool.sh
#
# This script will setup/build/run Hanson Robotics stack on you machine

set -e

BASEDIR=$(dirname $(readlink -f ${BASH_SOURCE[0]}))

### BEGIN: CONFIGURATIONS ###
HR_VERSION=0.1.2

PROJECT=${PROJECT:-HEAD}
OPENCOG_REPOS=(cogutils atomspace opencog ros-behavior-scripting relex external-tools)
HR_REPOS=($PROJECT)
GITHUB_STORAGE_URL=https://raw.githubusercontent.com/hansonrobotics/binary_dependency/master
declare -A MD5SUMS

DEFAULT_HR_WORKSPACE=~/hansonrobotics
HR_ENVFILE_PATH=~/.hr/env.sh
HR_PREFIX=/opt/hansonrobotics
HR_CACHE=$HOME/.hr/cache
HR_MODELS=$HOME/.hr/models
if [[ -z $APT_CACHE ]]; then
    APT_CACHE=0
fi
if [[ -z $PIP_CACHE ]]; then
    PIP_CACHE=0
fi
APT_CACHE_DIR=$HR_CACHE/archives
PIP_CACHE_DIR=$HR_CACHE/pip
LOG_DIR="$HOME/.hr/log"
VISION_TOOL_PREFIX=$HR_PREFIX/vision
DLIB_DIR=$VISION_TOOL_PREFIX/dlib
TORCH_DIR=$VISION_TOOL_PREFIX/torch
OPENFACE_DIR=$VISION_TOOL_PREFIX/openface
CPPMT_DIR=$VISION_TOOL_PREFIX/CppMT
EMOTIME_DIR=$VISION_TOOL_PREFIX/emotime
CLANDMARK_DIR=$VISION_TOOL_PREFIX/clandmark
MARKY_MARKOV_DIR=$HR_PREFIX/marky_markov
DLIB_VERSION=19.0

export PKG_CONFIG_PATH=${HR_PREFIX}/lib/pkgconfig:${PKG_CONFIG_PATH}
export DLIB_PATH=$DLIB_DIR/dlib-${DLIB_VERSION}

# Needed for compiling
export MANYEARSLIB_PREFIX=$HR_PREFIX/manyears-C-1.0.0
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CPPMT_DIR:$EMOTIME_DIR/build/src:$CLANDMARK_DIR/lib

INCLUDE_DIRS=($EMOTIME_DIR/src/{facedetector,utils,gaborbank,detector,training})
INCLUDE_PATH=$(printf "%s:" "${INCLUDE_DIRS[@]}")

export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:$CPPMT_DIR:$EMOTIME_DIR/include:$CLANDMARK_DIR/include:$INCLUDE_PATH
export LIBRARY_PATH=$LIBRARY_PATH:$CLANDMARK_DIR/lib/:$CPPMT_DIR:$EMOTIME_DIR/build/src:k
export PATH=/usr/lib/ccache:$PATH

ASSUME_YES=0

SUDO=""
if [[ $(id -u) != 0 ]]; then
    SUDO="sudo"
fi

APT_GET_OPTS="-y"
if [[ $APT_CACHE == 1 ]]; then
    APT_GET_OPTS="$APT_GET_OPTS -o dir::cache::archives=$APT_CACHE_DIR"
fi

PIP_OPTS=""
if [[ $PIP_CACHE == 1 ]]; then
    PIP_OPTS="$PIP_OPTS --download-cache $PIP_CACHE_DIR"
fi

### END: CONFIGURATIONS ###

### COMMON FUNCTIONS BEGIN ###
COLOR_INFO='\033[32m'
COLOR_WARN='\033[33m'
COLOR_ERROR='\033[31m'
COLOR_RESET='\033[0m'
if [[ ! -d $LOG_DIR/install ]]; then
    mkdir -p $LOG_DIR/install
fi
timestamp=$(date "+%Y%m%d%H%M%S")
LOG_FILE=$LOG_DIR/install/${timestamp}.log
ln -sf -T $LOG_FILE $LOG_DIR/install/latest.log

info() {
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    printf "${COLOR_INFO}[INFO] ${timestamp} $*${COLOR_RESET}\n" | tee -a $LOG_FILE
}
warn() {
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    printf "${COLOR_WARN}[WARN] ${timestamp} $*${COLOR_RESET}\n" | tee -a $LOG_FILE
}
error() {
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    printf "${COLOR_ERROR}[ERROR] ${timestamp} $*${COLOR_RESET}\n" | tee -a $LOG_FILE
}

md5str() {
  local FNAME=$1
  case $(uname) in
    "Linux")
      echo $(md5sum "$FNAME" | cut -d ' ' -f 1)
      ;;
    "Darwin")
      echo $(md5 -q "$FNAME")
      ;;
  esac
}

checkmd5() {
    local FNAME=$1
    if [[ ! -f $FNAME ]]; then
        error "$FNAME is not a file"
        return 1
    fi
    local EXPECTED=$2
    local ACTUAL=$(md5str "$FNAME")
    if [ $EXPECTED = $ACTUAL ]; then
        info "$FNAME: successfully checked"
        return 0
    else
        error "$FNAME md5sum did not match."
        error "Expected: $EXPECTED"
        error "Actual: $ACTUAL"
        mv ${FNAME} ${FNAME}.old && warn "$FNAME is removed"
        return 1
    fi
}

wget_cache() {
    url=$1
    ofile=${2-${url##*/}}
    info "Downloading $1"
    [[ -f ${HR_CACHE}/${ofile} ]] || wget ${url} -O ${HR_CACHE}/${ofile}

    # check md5sum
    local sum=${MD5SUMS[$ofile]}
    local retry=1
    if [[ ! -z $sum ]]; then
        while (( $retry >= 0 )); do
            if checkmd5 ${HR_CACHE}/${ofile} $sum; then
                break
            fi
            retry=$((retry-1))
            echo $retry
            if (( $retry >= 0 )); then
                wget ${url} -O ${HR_CACHE}/${ofile}
            fi
        done
    fi

    info "Downloading $1 is done"
}

curl_cache() {
    url=$1
    ofile=${2-${url##*/}}
    info "Downloading $1"
    [[ -f ${HR_CACHE}/${ofile} ]] || curl -L ${url} -o ${HR_CACHE}/${ofile}

    # check md5sum
    local sum=${MD5SUMS[$ofile]}
    local retry=1
    if [[ ! -z $sum ]]; then
        while (( $retry >= 0 )); do
            if checkmd5 ${HR_CACHE}/${ofile} $sum; then
                break
            fi
            retry=$((retry-1))
            echo $retry
            if (( $retry >= 0 )); then
                curl -L ${url} -o ${HR_CACHE}/${ofile}
            fi
        done
    fi

    info "Downloading $1 is done"
}

timeit() {
    local start=$(date +%s.%N)
    $@
    local elapsed=$(echo "$(date +%s.%N)-$start" | bc)
    info "Command \"$1\", time used $elapsed"
}

### COMMON FUNCTIONS END ###

check_apt_installed() {
    # Check if the given debian packages are installed
    local pkgs=$@
    local s
    local v
    local ver
    local pkg
    for pkg in $pkgs; do
        if [[ ${pkg} =~ .*"=".* ]]; then
            ver=${pkg##*=}
            pkg=${pkg%=*}
            s=$(dpkg-query -W -f='${db:Status-Abbrev}=${Version}' "$pkg")
            v=${s##*=}
            s=${s%=*}
            if [[ $ver != $v || ${#s} != 3 || ${s:1:1} != 'i' ]]; then
                return 1
            else
                info "$pkg=$ver is already installed"
            fi
        else
            s=$(dpkg-query -W -f='${db:Status-Abbrev}' "$pkg")
            if [[ ${#s} != 3 || ${s:1:1} != 'i' ]]; then
                return 1
            else
                info "$pkg is already installed"
            fi
        fi
    done
}

add_ppa() {
    user=$(echo $1|cut -d: -f2|cut -d/ -f1)
    ppa=$(echo $1|cut -d: -f2|cut -d/ -f2)
    for file in `find /etc/apt/ -name \*.list`; do
        set +e
        item=$(grep -o "^deb http://ppa.launchpad.net/[a-z0-9\-]\+/[a-z0-9\-]\+" $file)
        set -e
        USER=`echo $item | cut -d/ -f4`
        PPA=`echo $item | cut -d/ -f5`
        if [[ $USER == $user && $PPA == $ppa ]]; then
            info "PPA $1 is already added"
            return 0
        fi
    done
    info $SUDO add-apt-repository -y $1
    $SUDO add-apt-repository -y $1
}

apt_get_install() {
    if ! check_apt_installed "$@"; then
        $SUDO apt-get ${APT_GET_OPTS} install "$@" || (
            $SUDO apt-get ${APT_GET_OPTS} update &&
            $SUDO apt-get ${APT_GET_OPTS} install "$@")
    fi
}

install_basic() {
    info "Installing basic dependencies"
    local pkgs=(git wget telnet python3-pip python-pip build-essential
            software-properties-common)
    apt_get_install "${pkgs[@]}"
    info "Installing basic dependencies is done"
}

install_ros() {
    info "Installing ROS"
    $SUDO sh -c 'echo "deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main" > /etc/apt/sources.list.d/ros-latest.list'
    $SUDO apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net --recv-key 0xB01FA116
    local pkgs=(
        ros-indigo-desktop
        ros-indigo-tf
        ros-indigo-driver-common
        ros-indigo-cv-bridge
        ros-indigo-image-transport
        ros-indigo-openni-camera
        ros-indigo-mjpeg-server
        ros-indigo-usb-cam
        ros-indigo-dynamixel-motor
        ros-indigo-robot-state-publisher
        ros-indigo-joint-state-publisher
        ros-indigo-rosbridge-server
        python-catkin-tools
    )

    # for camera calibration
    pkgs+=(ros-indigo-image-proc)

    apt_get_install "${pkgs[@]}"

    # for blender to find ros packages
    $SUDO pip3 install ${PIP_OPTS} rospkg catkin_pkg

    if [[ ! -f /etc/ros/rosdep/sources.list.d/20-default.list ]]; then
        $SUDO rosdep init -q
        rosdep update -q
    fi
    info "Installing ROS is done"
}

install_opencog_deps() {
    info "Installing OpenCog dependencies"
    local pkgs=(
        cmake ccache
        binutils-dev
        libboost-dev libboost-date-time-dev libboost-filesystem-dev
        libboost-program-options-dev libboost-regex-dev
        libboost-serialization-dev libboost-system-dev libboost-thread-dev
        guile-2.0-dev cython
    )
    apt_get_install "${pkgs[@]}"

    wget http://raw.github.com/opencog/ocpkg/master/ocpkg -qO octool
    chmod +rx octool
    ./octool -dpv
    rm octool

    # For sentiment analysis
    $SUDO pip2 install ${PIP_OPTS} nltk
    $SUDO python -m nltk.downloader -d /usr/local/share/nltk_data punkt averaged_perceptron_tagger

    # For random sentence generator
    install_marky_markov

    install_relex_deps

    info "Installing OpenCog dependencies is done"
}

install_link_grammar() {
    info "Installing Link-Grammar"

    MD5SUMS["link-grammar-5.3.13.tar.gz"]=d519ff9f404bbda5bfe229839272d91c
    wget_cache $GITHUB_STORAGE_URL/link-grammar-5.3.13.tar.gz

    rm -rf /tmp/link-grammar-5.3.13
    tar -zxf ${HR_CACHE}/link-grammar-5.3.13.tar.gz -C /tmp
    mkdir -p /tmp/link-grammar-5.3.13/build
    cd /tmp/link-grammar-5.3.13/build
    JAVA_HOME=/usr/lib/jvm/default-java
    ../configure
    make -j$(nproc)
    $SUDO make install
    $SUDO ldconfig
    rm -rf /tmp/link-grammar-5.3.13
    cd $BASEDIR
    info "Installing Link-Grammar done"
}

install_relex_deps() {
    info "Installing RelEX dependencies"
    local pkgs=(
        build-essential python-dev swig zlib1g-dev unzip wget
        wordnet-dev wordnet-sense-index
        openjdk-7-jdk
        ant libcommons-logging-java libgetopt-java
    )
    apt_get_install "${pkgs[@]}"

    if [[ ! -e /usr/local/lib/liblink-grammar.so ]]; then
        install_link_grammar
    fi

    # Java WordNet Library
    if [[ ! -e /usr/local/share/java/jwnl.jar ]]; then
        MD5SUMS["jwnl14-rc2.zip"]=c1c35ce1d1590938abe48d7785f87ae0
        wget_cache $GITHUB_STORAGE_URL/jwnl14-rc2.zip
        unzip -qo ${HR_CACHE}/jwnl14-rc2.zip -d /tmp jwnl14-rc2/jwnl.jar
        $SUDO mv -v /tmp/jwnl14-rc2/jwnl.jar /usr/local/share/java/
        rm -r /tmp/jwnl14-rc2
        $SUDO chmod -v 0644 /usr/local/share/java/jwnl.jar
    fi
    info "Installing RelEX dependencies is done"
}

install_pocketsphinx() {
    if [[ -f /opt/hansonrobotics/lib/pkgconfig/pocketsphinx.pc && -f /opt/hansonrobotics/lib/pkgconfig/sphinxbase.pc ]]; then
        info "Pocketsphinx is already installed."
        return
    fi
    info "Installing Pocketsphinx"
    apt_get_install bison automake
    MD5SUMS["sphinxbase-1.0.0.tar.gz"]=df69f72b19abd943cfc4b51ec30a3b29
    MD5SUMS["pocketsphinx-1.0.0.tar.gz"]=b94bf391c22b6dd4c86a8c112aa62f48
    wget_cache https://github.com/hansonrobotics/sphinxbase/archive/v1.0.0.tar.gz sphinxbase-1.0.0.tar.gz
    wget_cache https://github.com/hansonrobotics/pocketsphinx/archive/v1.0.0.tar.gz pocketsphinx-1.0.0.tar.gz

    tar zxf ${HR_CACHE}/sphinxbase-1.0.0.tar.gz -C /tmp
    cd /tmp/sphinxbase-1.0.0
    ./autogen.sh && ./configure --prefix=$HR_PREFIX && make && make install
    rm -r /tmp/sphinxbase-1.0.0

    tar zxf ${HR_CACHE}/pocketsphinx-1.0.0.tar.gz -C /tmp
    cd /tmp/pocketsphinx-1.0.0
    ./autogen.sh && ./configure --prefix=$HR_PREFIX && make && make install
    rm -r /tmp/pocketsphinx-1.0.0
    cd $BASEDIR
    info "Installing Pocketsphinx is done"
}

install_blender() {
    info "Installing blender"
    add_ppa ppa:irie/blender
    apt_get_install blender
    info "Installing blender done"
}

install_ffmpeg() {
    info "Installing ffmpeg"
    # For blender_api_test
    add_ppa ppa:mc3man/trusty-media
    apt_get_install ffmpeg
    info "Installing ffmpeg done"
}

install_tts() {
    # For Festival
    apt_get_install festival festival-dev

    # Install female voice
    mkdir -p ~/.hr/tts/festival/voices
    # Install female voice
    if [[ ! -f ~/.hr/tts/festival/voices/festvox_cmu_us_slt_arctic_hts.tar.gz ]]; then
        MD5SUMS["festvox_cmu_us_slt_arctic_hts.tar.gz"]=a9b53441968f6bc612b85c04bbc4cf0f
        wget_cache http://festvox.org/packed/festival/2.1/festvox_cmu_us_slt_arctic_hts.tar.gz
        cp ${HR_CACHE}/festvox_cmu_us_slt_arctic_hts.tar.gz $HOME/.hr/tts/festival/voices
    fi
    tar zxf ~/.hr/tts/festival/voices/festvox_cmu_us_slt_arctic_hts.tar.gz -C /tmp
    $SUDO cp -rT /tmp/festival/lib/voices /usr/share/festival/voices
    rm -rf /tmp/festival

    # MaryTTS
    mkdir -p ~/.hr/tts/marytts
    MD5SUMS["marytts-5.1.2.zip"]=99e774dd4c6e791ad916ae76351522f0
    wget_cache https://github.com/marytts/marytts/releases/download/v5.1.2/marytts-5.1.2.zip
    unzip -qod ~/.hr/tts/marytts ${HR_CACHE}/marytts-5.1.2.zip
}

install_other_deps() {
    info "Installing other dependencies"
    local pkgs=()

    # For rosbridge_server
    pkgs+=(python-bson)

    # For pololu-motors
    # DO NOT UPGRADE WITH PIP
    pkgs+=(python-serial)

    # For Blender
    pkgs+=(python3-numpy)

    # For running scripts
    pkgs+=(tmux)

    # For tts playing audio
    pkgs+=(python-pyglet)

    # For chatbot
    pkgs+=(python-yaml)

    # Swig for iflytek SDK
    pkgs+=(swig)

    # For rospy to run with python3
    pkgs+=(python3-yaml)

    # For telnet automation
    pkgs+=(expect)

    # For audio recording
    pkgs+=(pulseaudio python-pyaudio)

    # For window layout
    pkgs+=(xdotool)

    apt_get_install "${pkgs[@]}"

    # For chatbot
    $SUDO pip2 install num2words

    # For Chinese tts
    $SUDO pip2 install ${PIP_OPTS} pinyin==0.2.5

    # For speech2command
    $SUDO pip2 install ${PIP_OPTS} pyparsing

    # For performances
    $SUDO pip2 install transitions

    # For webui
    $SUDO pip2 install ${PIP_OPTS} flask EasyProcess psutil

    info "Installing other dependencies is done"
}

install_manyears_deps() {
    info "Installing Manyears dependencies"
    if [[ ! -e $MANYEARSLIB_PREFIX/bin/libmanyears.a ]]; then
        # FOR GUI to build $SUDO apt-get ${APT_GET_OPTS} install qtmobility-dev
        MD5SUMS["manyears.tar.gz"]=cf8688959e6d6a7ea9cdd1167814862a
        wget_cache https://github.com/hansonrobotics/manyears-C/archive/v1.0.0.tar.gz manyears.tar.gz
        mkdir -p $MANYEARSLIB_PREFIX
        tar zxf $HR_CACHE/manyears.tar.gz --strip-components 1 -C $MANYEARSLIB_PREFIX
        mkdir -p $MANYEARSLIB_PREFIX/build && cd $MANYEARSLIB_PREFIX/build && cmake .. && make && $SUDO make install
    else
        info "Manyears is already installed"
    fi
    info "Installing Manyears dependencies is done"
}

install_test_deps() {
    info "Installing test dependencies"
    apt_get_install socat

    # WebUI compatable webserver
    $SUDO npm install xmlhttprequest --prefix $HR_WORKSPACE/$PROJECT/src/chatbot/scripts
    info "Installing test dependencies is done"
}

install_webui_deps() {
    # Remove npm and nodejs if needed
    # sudo npm uninstall -g npm
    # sudo apt-get remove nodejs

    # See https://github.com/nodesource/distributions#debinstall
    if ! hash nodejs; then
        info "Installing nodejs"
        curl -sL https://deb.nodesource.com/setup_6.x | $SUDO -E bash -
        apt_get_install nodejs
        info "Installing nodejs done"
    fi
    if ! npm ls -g webpack >/dev/null; then
        $SUDO npm install -g webpack
    fi
    if ! npm ls -g nodemon >/dev/null; then
        $SUDO npm install -g nodemon
    fi
}

install_dlib() {
    if [[ ! -e $DLIB_PATH/dist/dlib/dlib.so ]]; then
      info "Installing dlib"
      # The dlib DNS server sometimes times out. Pinging it first
      # makes it much more likely that the wget will succeed.
      ping -c 5 dlib.net
      MD5SUMS["dlib-${DLIB_VERSION}.tar.bz2"]=da930a35c2aa88612dd2ebf893f48f60
      wget_cache http://dlib.net/files/dlib-${DLIB_VERSION}.tar.bz2
      mkdir -p $DLIB_PATH
      tar -xf $HR_CACHE/dlib-${DLIB_VERSION}.tar.bz2 -C $DLIB_DIR
      cd $DLIB_PATH && python setup.py build
      info "Installing dlib is done"
    else
      warn "Skipping dlib installation"
    fi

}

install_clandmarks() {
    # Install clandmarks
    if [ ! -d $CLANDMARK_DIR ]; then
      info "Installing clandmarks"
      MD5SUMS["clandmark.tar.bz2"]=0d1eb90bad2c02fb38aed4e464555f02
      wget_cache $GITHUB_STORAGE_URL/clandmark.tar.bz2
      mkdir -p $CLANDMARK_DIR
      tar -xf $HR_CACHE/clandmark.tar.bz2 -C $CLANDMARK_DIR --strip-components=1
      info "Installing clandmarks is done"
    else
      warn "Skipping clandmark downloading"
    fi
}

install_torch() {
    if [ ! -d $TORCH_DIR ]; then
        info "Installing torch"
        git clone https://github.com/torch/distro.git $TORCH_DIR --recursive

        cd $TORCH_DIR
        bash install-deps
        echo no | ./install.sh

        # Install lua packages in the torch file in scripts directory.
        info "Installing lua packages"
        cd $TORCH_DIR/install/bin
        ./luarocks install nn
        ./luarocks install dpnn
        ./luarocks install image
        ./luarocks install optim
        ./luarocks install csvigo
        ./luarocks install sys
        info "Installing lua packages is done"
        info "Installing torch is done"
        cd $BASEDIR
    else
        warn "Skipping Torch installation"
    fi
}

install_openface() {
    info "Installing openface"
    # This is to install scikit-images as the pip version requires cython0.23 which can't be installed otherwise.
    apt_get_install python-skimage
    $SUDO pip2 install ${PIP_OPTS} numpy pandas scipy scikit-learn

    if [ ! -d $OPENFACE_DIR ]; then
      info "Cloning openface"
      git clone https://github.com/hansonrobotics/openface.git $OPENFACE_DIR --recursive
    else
      warn "Skipping openface clone"
    fi
    info "Installing openface is done"

    # $OPENFACE_DIR/models/get-models.sh
    MD5SUMS["nn4.small2.v1.t7"]=c95bfd8cc1adf05210e979ff623013b6
    MD5SUMS["celeb-classifier.nn4.small2.v1.pkl"]=199a2c0d32fd0f22f14ad2d248280475
    MD5SUMS["shape_predictor_68_face_landmarks.dat.bz2"]=677a91476056de0507f1915adc7ef86a
    wget_cache http://openface-models.storage.cmusatyalab.org/nn4.small2.v1.t7
    wget_cache http://openface-models.storage.cmusatyalab.org/celeb-classifier.nn4.small2.v1.pkl
    if [[ ! -f ${HR_CACHE}/shape_predictor_68_face_landmarks.dat ]]; then
        wget_cache http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
        bunzip2 -f ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2
    fi
    checkmd5 ${HR_CACHE}/celeb-classifier.nn4.small2.v1.pkl 199a2c0d32fd0f22f14ad2d248280475
    mkdir -p $OPENFACE_DIR/models/dlib
    mkdir -p $OPENFACE_DIR/models/openface
    cp ${HR_CACHE}/shape_predictor_68_face_landmarks.dat ${OPENFACE_DIR}/models/dlib
    cp ${HR_CACHE}/nn4.small2.v1.t7 ${OPENFACE_DIR}/models/openface
    cp ${HR_CACHE}/celeb-classifier.nn4.small2.v1.pkl ${OPENFACE_DIR}/models/openface
}

install_cmt() {
    if [ ! -d $CPPMT_DIR ]; then
        info "Cloning CppMT"
        git clone https://github.com/hansonrobotics/CppMT.git $CPPMT_DIR
        cd $CPPMT_DIR
        git checkout wrapper
    else
        warn "Skipping CppMT clone"
    fi

    if [ ! -f $CPPMT_DIR/cmt ]; then
        cd $CPPMT_DIR
        cmake .
        make -j$(nproc)
    fi
    cd $BASEDIR
}

install_emotime() {
    if [ ! -d $EMOTIME_DIR ]; then
      info "Cloning emotime"
      git clone https://github.com/hansonrobotics/emotime.git $EMOTIME_DIR
    else
      warn "Skipping emotime clone"
    fi
    cd $EMOTIME_DIR/build
    cmake ..
    make -j$(nproc)
}

install_vision_deps() {
    info "Installing vision dependencies"
    mkdir -p $VISION_TOOL_PREFIX
    apt_get_install libopencv-dev ros-indigo-opencv-apps

    # Tkinter error other wise.
    $SUDO pip2 install ${PIP_OPTS} -I Pillow
    $SUDO pip2 install ${PIP_OPTS} imgurpython

    install_dlib
    install_clandmarks
    install_torch
    install_openface
    install_cmt
    install_emotime

    info "Installing vision dependencies is done"
}

install_marky_markov() {
    info "Installing Marky Markov"
    if [ ! -d $MARKY_MARKOV_DIR ]; then
      git clone https://github.com/hansonrobotics/marky_markov.git $MARKY_MARKOV_DIR
    else
      warn "Skipping marky_markov clone"
    fi
    MD5SUMS["markov_modeling.tar.gz"]=7d51bbcd4df89b2633bd9520fb99b2b7
    wget_cache $GITHUB_STORAGE_URL/markov_modeling.tar.gz
    [[ ! -d $HR_MODELS ]] && mkdir -p $HR_MODELS
    tar zxf ${HR_CACHE}/markov_modeling.tar.gz -C $HR_MODELS

    add_ppa ppa:brightbox/ruby-ng
    apt_get_install ruby2.3 ruby2.3-dev
    $SUDO gem install marky_markov
    info "Installing Marky Markov is done"
}

install_calib_tools() {
    MD5SUMS["maestro-linux-150116.tar.gz"]=84feed740c0695bb0eea13ccf7988b97
    wget_cache $GITHUB_STORAGE_URL/maestro-linux-150116.tar.gz
    mkdir -p ${HR_PREFIX}/maestro
    tar zxf ${HR_CACHE}/maestro-linux-150116.tar.gz -C ${HR_PREFIX}/maestro --strip-components 1
    apt_get_install libusb-1.0-0-dev mono-runtime libmono-winforms2.0-cil
    $SUDO cp ${HR_PREFIX}/maestro/99-pololu.rules /etc/udev/rules.d/
    $SUDO udevadm control --reload-rules

    MD5SUMS["mx_calib"]=5e34a64564df92c116f027a9ff48a11b
    wget_cache $GITHUB_STORAGE_URL/mx_calib
    if [[ ! -f ${HR_PREFIX}/mx_calib ]]; then
        cp ${HR_CACHE}/mx_calib ${HR_PREFIX}
    fi
    chmod +x ${HR_PREFIX}/mx_calib
}

get_models() {
    _get_models
}

_get_models() {
    [[ ! -d $HR_MODELS ]] && mkdir -p $HR_MODELS
    local old_dir=${HOME}/.hr/cache/models
    if [[ -d ${old_dir} ]]; then
        for f in ${old_dir}/*; do
            [[ -f "$f" ]] || continue
            if [[ ! -e ${HR_MODELS}/${f##*/} ]]; then
                mv ${f} ${HR_MODELS}/
            fi
        done
    fi

    # openface
    wget_cache http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2
    wget_cache http://openface-models.storage.cmusatyalab.org/nn4.small2.v1.t7
    checkmd5 ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2 677a91476056de0507f1915adc7ef86a
    checkmd5 ${HR_CACHE}/nn4.small2.v1.t7 c95bfd8cc1adf05210e979ff623013b6
    cp ${HR_CACHE}/shape_predictor_68_face_landmarks.dat.bz2 ${HR_MODELS}
    bunzip2 -f ${HR_MODELS}/shape_predictor_68_face_landmarks.dat.bz2
    cp ${HR_CACHE}/nn4.small2.v1.t7 ${HR_MODELS}

    # markov
    wget_cache https://github.com/opencog/test-datasets/releases/download/current/markov_modeling.tar.gz
    checkmd5 ${HR_CACHE}/markov_modeling.tar.gz 7d51bbcd4df89b2633bd9520fb99b2b7
    tar zxf ${HR_CACHE}/markov_modeling.tar.gz -C $HR_MODELS
}

check_or_create_ws() {
    [[ ! -z $1 ]]
    if [[ ! -d $1 ]]; then
        local confirm
        _get_confirm "The workspace ${1} does not exist, create? [y/N]"
        if [[ ${confirm} -eq 1 ]]; then
            mkdir -p ${1}
            echo "Workspace directory ${1} is created"
        fi
    fi
}

clone() {
    owner=$1
    repo=$2
    dest=${3-"."}/$repo
    # if ssh clone failed, then try https clone
    if [[ -d $dest ]]; then
        info "$dest already exists"
    else
        info "Cloning $repo"
        git clone git@github.com:$owner/$repo.git $dest || git clone https://github.com/$owner/$repo.git $dest
        info "Cloning $repo is done"
    fi
}

get_opencog_src(){
    info "Cloning OpenCog source code"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE
        clone hansonrobotics $repo opencog
    done
    info "Cloning OpenCog source code is done"
}

check_local_changes() {
    for repo in ${OPENCOG_REPOS[*]}
    do
        if [[ -d $HR_WORKSPACE/opencog/$repo ]]; then
            cd $HR_WORKSPACE/opencog/$repo
            branch=$(git rev-parse --abbrev-ref HEAD)
            if [[ $branch != 'master' ]]; then
                warn "HEAD branch is not master $(pwd)" 1>&2
                return 1
            fi
            if [[ $(git status -uno --porcelain|wc -c) != 0 ]]; then
                warn "Plese commit the change(s) $(pwd)" 1>&2
                warn $(git status --porcelain) 1>&2
                return 1
            fi
            if [[ $(git diff --name-only master origin/master|wc -c) != 0 ]]; then
                warn "Master branch is not synchronized with origin $(pwd)" 1>&2
                return 1
            fi
        fi
    done
    cd $HR_WORKSPACE
}

update_opencog() {
    info "Updating OpenCog source code"
    local DEFAULT_BRANCH="master"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE/opencog/$repo
        branch=$(git rev-parse --abbrev-ref HEAD)
        if [[ $branch != $DEFAULT_BRANCH ]]; then
            warn "[${repo}] Branch is not (${DEFAULT_BRANCH}) branch (${branch}). Skip."
            continue
        fi
        info "Updating [${repo}]"
        git pull origin $DEFAULT_BRANCH
        info "Updating [${repo}] is done"
    done
    info "Updating OpenCog source code is done"
}

do_update_hr() {
    info "Updating HR source code"
    do_migrate

    local DEFAULT_BRANCH="master"
    for repo in ${HR_REPOS[*]}
    do
        cd $HR_WORKSPACE/$repo
        branch=$(git rev-parse --abbrev-ref HEAD)
        if [[ $branch != $DEFAULT_BRANCH ]]; then
            warn "[${repo}] Branch is not (${DEFAULT_BRANCH}) branch (${branch}). Skip."
            continue
        fi
        info "Updating [${repo}]"
        git pull origin $DEFAULT_BRANCH
        info "Updating [${repo}] is done"
    done
    do_update_vision_tools
    info "Updating HR source code is done"
}

do_update_vision_tools() {
    #Update CMT
    if [[ ! -d $CPPMT_DIR ]]; then
        warn "CppMT doesn't exist"
        return
    fi
    local DEFAULT_BRANCH="wrapper"
    cd $CPPMT_DIR
    repo=CppMT
    branch=$(git rev-parse --abbrev-ref HEAD)
    if [[ $branch != $DEFAULT_BRANCH ]]; then
        warn "[${repo}] Branch is not (${DEFAULT_BRANCH}) branch (${branch}). Skip."
        continue
    fi
    info "Updating [$repo]"
    git pull origin $DEFAULT_BRANCH
    info "Updating [$repo] is done"
}

do_install_deps() {
    info "Installing dependencies"
    _do_install_deps
    info "Installing dependencies is done"
}

_do_install_deps() {
    if [[ ! -d $HR_PREFIX ]]; then
        info "Creating $HR_PREFIX"
        $SUDO mkdir -p $HR_PREFIX
    fi
    $SUDO chmod 777 $HR_PREFIX
    timeit install_basic
    timeit install_ros
    timeit install_opencog_deps
    timeit install_vision_deps
    timeit install_manyears_deps
    timeit install_webui_deps
    timeit install_blender
    timeit install_ffmpeg
    timeit install_tts
    timeit install_pocketsphinx
    timeit install_calib_tools
    timeit install_other_deps
    timeit get_models

    wget_cache https://raw.githubusercontent.com/hansonrobotics/HEAD/master/scripts/patch/rosbridge.patch
    $SUDO patch -N /opt/ros/indigo/lib/python2.7/dist-packages/rosbridge_library/internal/publishers.py ${HR_CACHE}/rosbridge.patch || true
}

do_get_hr_src() {
    info "Cloning HR source code"
    for repo in ${HR_REPOS[*]}
    do
        cd $HR_WORKSPACE
        clone hansonrobotics $repo
    done
    info "Cloning HR source code is done"
}

do_get_src() {
    # Check/add the github host key to ~/.ssh/known_hosts
    ssh -o StrictHostKeyChecking=no github.com || true
    do_get_hr_src
    get_opencog_src
}

do_dev_mode() {
    DOMAIN=${1-"opencog"}
    check_local_changes || exit 1
    warn "Switching to $DOMAIN repositories"
    for repo in ${OPENCOG_REPOS[*]}
    do
        cd $HR_WORKSPACE
        if [[ -d $HR_WORKSPACE/opencog/$repo ]]; then
            info "Set [$repo] origin to https://github.com/$DOMAIN/$repo"
            cd opencog/$repo
            git remote remove old || true
            git remote rename origin old
            git remote add -f origin https://github.com/$DOMAIN/$repo
            git branch master -u origin/master
            git reset --hard origin/master
        else
            clone $DOMAIN $repo opencog
        fi
    done
    update_opencog
}

undo_dev_mode() {
    do_dev_mode hansonrobotics
}

do_build_hr() {
    info "Building HR"
    _do_build_hr
    info "Building HR is done"
}

pack_hr() {
    if [[ ! -d makeself ]]; then
        MD5SUMS["makeself-2.2.0.tar.gz"]=8075530b2ad0a2fbd4bffa80a96eb2ea
        wget_cache https://github.com/megastep/makeself/archive/release-2.2.0.tar.gz makeself-2.2.0.tar.gz
        mkdir -p makeself
        tar zxf ${HR_CACHE}/makeself-2.2.0.tar.gz -C makeself --strip-components 1
    fi
    TIME=$(date +%Y%m%d%H%M%S)
    makeself/makeself.sh ${HR_WORKSPACE}/HEAD/install HEAD-${TIME}.run "HEAD" .
    rm -rf makeself
}

_do_build_hr() {
    # build CppMT
    if [[ -d $CPPMT_DIR ]]; then
        cd $CPPMT_DIR
        info "Building CPPMT"
        cmake .
        make -j$(nproc)
    fi

    cd $HR_WORKSPACE/$PROJECT
    source /opt/ros/indigo/setup.bash
    if [[ ! -d .catkin_tools ]]; then
        catkin init
    fi

    catkin config --blacklist icog_face_tracker
    catkin clean -y || catkin clean -a
    catkin build --force-cmake -j$(nproc) --no-status --make-args install
    TARGET=$HR_WORKSPACE/$PROJECT/devel/lib/python2.7/dist-packages/
    pip2 install -t $TARGET $HR_WORKSPACE/$PROJECT/src/hardware/pololu-motors --upgrade --no-deps
    pip3 install -t $TARGET $HR_WORKSPACE/$PROJECT/src/blender_api_msgs --upgrade --no-deps
    cd $HR_WORKSPACE/$PROJECT/src/webui
    npm install
}

do_single_package() {
    cd $HR_WORKSPACE/$PROJECT
    source /opt/ros/indigo/setup.bash
    if [[ ! -d .catkin_tools ]]; then
        catkin init
    fi
    catkin build $1
}

build_opencog() {
    info "Building OpenCog"
    for repo in ${OPENCOG_REPOS[*]}
    do
        if [[ $repo != 'relex' ]]; then
            if [[ ! -d $HR_WORKSPACE/opencog/$repo/build ]]; then
                mkdir $HR_WORKSPACE/opencog/$repo/build
            fi
            cd $HR_WORKSPACE/opencog/$repo/build && cmake ..  && make -j$(nproc) && $SUDO make install
        else
            cd $HR_WORKSPACE/opencog/$repo && JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8 ant build && $SUDO ant install
        fi
    done
    info "Building OpenCog is done"
}

do_build() {
    build_opencog
    do_build_hr
}

do_test() {
    bash $HR_WORKSPACE/$PROJECT/scripts/test.sh
}

do_update() {
    update_opencog
    do_update_hr
}

do_clean_up() {
    info "Cleaning up"
    set +e
    _do_clean_up >/dev/null 2>&1
    set -e
    info "Cleaning up is done"
}

_do_clean_up() {
    rm -r ~/.cache/guile
    rm -r ~/.hr/cache/oc_aiml
    if [[ ! -z $HR_WORKSPACE ]]; then
        for repo in ${OPENCOG_REPOS[*]}
        do
            if [[ $repo != 'relex' ]]; then
                $SUDO rm -r $HR_WORKSPACE/opencog/$repo/build
            fi
        done
    fi
    $SUDO rm -r /usr/local/include/opencog
    $SUDO rm -r /usr/local/lib/opencog
    $SUDO rm -r /usr/local/share/opencog
    $SUDO rm /usr/local/bin/cogserver
    $SUDO rm /usr/local/etc/cogserver.conf
    $SUDO rm /usr/local/etc/opencog.conf
    $SUDO rm /usr/local/lib/libcogutil.so
}

_get_rel_ws() {
    readlink -f ${BASEDIR}/../../
}

_get_confirm() {
    local message="${1:-Are you sure?}"
    local answer
    if [ "$ASSUME_YES" -eq 1 ] ; then
        confirm=1
        return
    fi
    printf '%s ' "$message"
    read -r answer
    ! printf '%s\n' "$answer" | grep -Eq "$(locale yesexpr)"
    confirm=$?
}

check_ws() {
    # Check workspace
    local rel_ws=$(_get_rel_ws)
    local ws=$(readlink -f ${HR_WORKSPACE})
    if [[ $rel_ws != $ws ]]; then
        local confirm
        warn "The workspace configured ${ws} doesn't match the your working path ${rel_ws}"
        _get_confirm "Set workspace to your working path ${rel_ws}? [y/N]"
        if [[ ${confirm} -eq 1 ]]; then
            HR_WORKSPACE=${rel_ws}
            set_env
        else
            exit 1
        fi
    fi
}

#######

show_help() {
cat << EOF
Usage: $0 OPTION

-i      Install dependencies.
-g      Get HR source code.
-G      Get all source code including OpenCog and HR.
-u      Update HR source code.
-v      Update Vision Related dependencies.
-U      Update all source code including OpenCog and HR.
-b      Build HR source code.
-B      Build HR and OpenCog source code.
-t      Run tests.
-w      Set Hanson Robotics workspace.
-p      Print Hanson Robotics workspace.
-r      Run custom functions.
-d      Developer mode. Using latest OpenCog stack.
-c      Clean up files.
-h      Print this help.
-s      Build a single package specified.
-m      Migrate.
-P      Build package.
-y      Assume yes to all queries and don't prompt.

EOF
}

parse_opts() {
    while getopts ":hw:igGbBuUvtpr:s:dcmPy" opt; do
        case $opt in
        h)
            show_help
            exit 0
            ;;
        w) HR_WORKSPACE=$OPTARG ;;
        i) INSTALL_DEPENDENCIES=1 ;;
        g) GET_HR_SOURCE_CODE=1 ;;
        G) GET_SOURCE_CODE=1 ;;
        b) BUILD_HR_SOURCE_CODE=1 ;;
        B) BUILD_SOURCE_CODE=1 ;;
        u) UPDATE_HR_SOURCE_CODE=1 ;;
        U) UPDATE_SOURCE_CODE=1 ;;
        v) UPDATE_VISION_CODE=1 ;;
        t) RUN_TESTS=1 ;;
        p) PRINT_HR_WORKSPACE=1 ;;
        s) BUILD_SINGLE_PKG=1  && CUSTOM_FUNCTIONS=$OPTARG ;;
        r) RUN_CUSTOM_FUNCTIONS=1 && CUSTOM_FUNCTIONS=$OPTARG && break ;;
        d) DEVELOPER_MODE=1 ;;
        c) CLEANUP=1 ;;
        m) MIGRATE=1 ;;
        P) BUILD_PACKAGE=1 ;;
        y) ASSUME_YES=1 ;;
        \?)
            error "Invalid option: -$OPTARG" >&2
            show_help
            exit 1
            ;;
        :)
            error "Option -$OPTARG requires an argument." >&2
            show_help
            exit 1
            ;;
        esac
    done
    shift $((OPTIND-1))
    CUSTOM_FUNCTIONS_ARGS=$@
}

set_ws() {
    if [[ -z $HR_WORKSPACE ]]; then
        if [[ -f $HR_ENVFILE_PATH ]]; then
            local str=$(cat $HR_ENVFILE_PATH|grep "export HR_WORKSPACE=")
            if [[ -z $str ]]; then
                error "HR_WORKSPACE is not found in $HR_ENVFILE_PATH"
                local confirm
                _get_confirm "Do you want to reset to default ${DEFAULT_HR_WORKSPACE}? [y/N]"
                [[ ${confirm} -eq 1 ]] || exit 0
                HR_WORKSPACE=$DEFAULT_HR_WORKSPACE
            else
                HR_WORKSPACE=${str#export HR_WORKSPACE=}
            fi
        else
            HR_WORKSPACE=$DEFAULT_HR_WORKSPACE
        fi
    fi
    if [[ ! "$HR_WORKSPACE" = /* ]]; then
        HR_WORKSPACE=$(pwd)/$HR_WORKSPACE
    fi
    check_or_create_ws $HR_WORKSPACE
    if [[ ! -d $HR_WORKSPACE ]]; then
        error "HR_WORKSPACE is incorrect, exit"
        exit 1;
    fi
    if [[ ! -d $(dirname $HR_ENVFILE_PATH) ]]; then mkdir -p $(dirname $HR_ENVFILE_PATH); fi
    if [[ $HR_WORKSPACE != '/' ]]; then
        HR_WORKSPACE=${HR_WORKSPACE%/}
    fi
    echo export HR_WORKSPACE=$HR_WORKSPACE > $HR_ENVFILE_PATH
    export HR_WORKSPACE=$HR_WORKSPACE
}

set_env() {
    set_ws
cat <<EOF >>$HR_ENVFILE_PATH
export HR_VERSION=$HR_VERSION
export HR_ENVFILE_PATH=$HR_ENVFILE_PATH
export HR_PREFIX=$HR_PREFIX
export HR_CACHE=$HR_CACHE

export VISION_TOOL_PREFIX=$VISION_TOOL_PREFIX
export DLIB_DIR=$DLIB_DIR
export TORCH_DIR=$TORCH_DIR
export OPENFACE_DIR=$OPENFACE_DIR
export CPPMT_DIR=$CPPMT_DIR
export EMOTIME_DIR=$EMOTIME_DIR

export MARKY_MARKOV_DIR=$MARKY_MARKOV_DIR
export HR_MODELS=$HR_MODELS

export ROS_LOG_DIR="$HOME/.hr/log"
export OCBHAVE="$HR_WORKSPACE/opencog/ros-behavior-scripting"
export PYTHONPATH=$PYTHONPATH:$OCBHAVE/src:$OPENFACE_DIR:$DLIB_DIR/dlib-${DLIB_VERSION}/dist:/usr/local/share/opencog/python

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH
export LIBRARY_PATH=$LIBRARY_PATH
export DLIB_PATH=$DLIB_PATH
export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH
export MANYEARSLIB_PREFIX=$MANYEARSLIB_PREFIX

export CLANDMARK_DIR=$VISION_TOOL_PREFIX/clandmark
if [[ -f $TORCH_DIR/install/bin/torch-activate ]]; then
  source $TORCH_DIR/install/bin/torch-activate
fi
EOF

    cp $HR_ENVFILE_PATH $BASEDIR >/dev/null 2>&1 # For compatibility
}

_change_remote() {
    repo_url=$1
    branch=$2
    git remote remove old 2>&1 1>/dev/null || true
    git remote rename origin old
    git remote add -f origin $repo_url
    git branch $branch -u origin/$branch
    git reset --hard origin/$branch
}

do_migrate() {
    if [[ -d $EMOTIME_DIR ]]; then
        info "Migrating [emotime]"
        cd $EMOTIME_DIR &&  _change_remote https://github.com/hansonrobotics/emotime.git master
    fi
    if [[ -d $CPPMT_DIR ]]; then
        info "Migrating [CppMT]"
        cd $CPPMT_DIR && _change_remote https://github.com/hansonrobotics/CppMT.git wrapper
    fi
    if [[ -d $OPENFACE_DIR ]]; then
        info "Migrating [openface]"
        cd $OPENFACE_DIR && _change_remote https://github.com/hansonrobotics/openface.git master
    fi
}

do_build_package() {
    info "Building DEB package"
    # sudo apt-get ${APT_GET_OPTS} install packaging-dev
    local archive="head-${HR_VERSION}.tar.gz"
    local build_dir=$HR_WORKSPACE/build-area
    local workspace=${build_dir}/head-${HR_VERSION}
    info "Build directory ${build_dir}"
    cd $HR_WORKSPACE/$PROJECT
    git archive --format=tar.gz --prefix=head-${HR_VERSION}/ HEAD > $archive
    if [[ -d $workspace ]]; then
        rm -r $workspace
    fi
    mkdir -p ${build_dir}
    tar zxf $archive -C ${build_dir}
    cd $workspace

    install_target=$workspace/install/lib/python2.7/dist-packages/
cat <<EOF > _build.sh
#!/usr/bin/env bash
set -e
source /opt/ros/indigo/setup.bash
catkin init
catkin build -c -j$(nproc) --make-args install
pip2 install -t $install_target $workspace/src/hardware/pololu-motors --upgrade --no-deps
pip3 install -t $install_target $workspace/src/blender_api_msgs --upgrade --no-deps
EOF

cat <<EOF > _clean.sh
#!/usr/bin/env bash
set -e
catkin init
catkin clean -y || true
rm -rf .catkin_tools
rm -f $workspace/scripts/env.sh
EOF

    dh_make --yes --single --createorig || true
    dpkg-buildpackage -b
}

execute() {
    parse_opts $@
    set_env

    if [[ $DEVELOPER_MODE == 1 ||
        $UPDATE_HR_SOURCE_CODE == 1 ||
        $UPDATE_SOURCE_CODE == 1 ||
        $BUILD_HR_SOURCE_CODE == 1 ||
        $BUILD_SOURCE_CODE == 1 ||
        $RUN_CUSTOM_FUNCTIONS == 1 ||
        $BUILD_PACKAGE == 1
        ]]; then
        if [[ $ASSUME_YES == 0 ]] ; then
            check_ws
        fi
    fi
    if [[ $INSTALL_DEPENDENCIES ]]; then timeit do_install_deps; fi
    if [[ $GET_HR_SOURCE_CODE ]]; then timeit do_get_hr_src; fi
    if [[ $GET_SOURCE_CODE ]]; then timeit do_get_src; fi
    if [[ $DEVELOPER_MODE ]]; then timeit do_dev_mode ; fi
    if [[ $UPDATE_HR_SOURCE_CODE ]]; then timeit do_update_hr ; fi
    if [[ $UPDATE_SOURCE_CODE ]]; then timeit do_update ; fi
    if [[ $CLEANUP ]]; then timeit do_clean_up ; fi
    if [[ $BUILD_HR_SOURCE_CODE ]]; then timeit do_build_hr; fi
    if [[ $UPDATE_VISION_CODE ]]; then timeit do_update_vision_tools; fi
    if [[ $BUILD_SOURCE_CODE ]]; then timeit do_build; fi
    if [[ $RUN_TESTS ]]; then timeit do_test; fi
    if [[ $PRINT_HR_WORKSPACE ]]; then echo HR_WORKSPACE=$HR_WORKSPACE ; fi
    if [[ $BUILD_SINGLE_PKG ]]; then timeit do_single_package $CUSTOM_FUNCTIONS ; fi
    if [[ $RUN_CUSTOM_FUNCTIONS ]]; then timeit $CUSTOM_FUNCTIONS $CUSTOM_FUNCTIONS_ARGS; fi
    if [[ $MIGRATE ]]; then timeit do_migrate ; fi
    if [[ $BUILD_PACKAGE ]]; then timeit do_build_package ; fi
}

### Main ###

if [[ ! $(lsb_release --codename --short) == "trusty" ]]; then
    error "Error: Only Ubuntu 14.04 (trusty) is supported" >&2
    exit 1
fi

for i in $(env|grep ROS|cut -d= -f1); do
    unset $i
done
unset HR_WORKSPACE

for d in $HR_CACHE $APT_CACHE_DIR $PIP_CACHE_DIR; do
    if [[ ! -d ${d} ]]; then
        info "Creating ${d}"
        mkdir -p ${d}
    fi
done

if [[ ! $BASH_SOURCE == $0 ]]; then return; fi

if [ $# -eq 0 ] ; then show_help; exit 0; fi

execute $@
